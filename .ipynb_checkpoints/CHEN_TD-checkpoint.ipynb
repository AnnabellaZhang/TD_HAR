{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该部分代码是在Li_WISDM.ipynb基础上，调整时间窗与采样频率组合，做相应适应性分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文件中读取数据，加载函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "from tsfresh.examples.har_dataset import download_har_dataset, load_har_dataset, load_har_classes\n",
    "# import seaborn as sns\n",
    "from localtsfresh.tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from localtsfresh.tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import logging\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import butter, lfilter, lfilter_zi\n",
    "from numpy import linalg as LA\n",
    "from xgboost import XGBClassifier\n",
    "import copy\n",
    "from collections import Counter\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "print(cpu_count())\n",
    "\n",
    "# We set the logger to Error level\n",
    "# This is not recommend for normal use as you can oversee important Warning messages\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "#根据Win，生成DataFrame格式中的Time列\n",
    "def getTimeColumn(win):\n",
    "    time=np.arange(win)\n",
    "    for idx in range(1, sensornum):\n",
    "        timetmp=np.arange(win)\n",
    "        time=np.concatenate((time, timetmp), axis=0)\n",
    "    time.shape=(len(time),1)\n",
    "    return time\n",
    "\n",
    "#根据Win和数据，生成DataFrame格式中的kind和value列\n",
    "def getKindValueColumn(sd, win):\n",
    "    for i in range(sensornum):\n",
    "        kind=i*np.ones((win, 1),dtype=int)\n",
    "        sensorcols=sd[i]\n",
    "        sensorcols.shape=(win, 1)\n",
    "        sdata=np.column_stack((kind, sensorcols))\n",
    "        if i==0:\n",
    "            sensorframe=sdata\n",
    "        else:\n",
    "            sensorframe=np.row_stack((sensorframe, sdata))\n",
    "    return sensorframe\n",
    "\n",
    "def getIdColumn(num, win):\n",
    "    for i in range(num):\n",
    "        if i==0:\n",
    "            idary=0*np.ones((sensornum*win, 1))\n",
    "        else:\n",
    "            idary=np.row_stack((idary, i*np.ones((sensornum*win, 1))))\n",
    "    return idary\n",
    "\n",
    "def getDataLabelColumn(dataary,label, num, win):\n",
    "    for i in range(filenum):\n",
    "        if i==0:\n",
    "            y=label[travel[i]][:num]\n",
    "            data=dataary[travel[i]][:num*win*sensornum]\n",
    "        else:\n",
    "            y=np.row_stack((y, label[travel[i]][:num]))\n",
    "            data=np.row_stack((data, dataary[travel[i]][:num*win*sensornum]))\n",
    "    y.shape=(len(y),)\n",
    "    y=pd.Series(y)\n",
    "    return data, y\n",
    "\n",
    "\n",
    "#读取所有数据，结果是字典，分别存储六种运动的传感器读数矩阵，每个矩阵的三列分别是time, kind, value\n",
    "def loadData(win, step, fs, sampling):\n",
    "    labeldict={}\n",
    "    datadict={}\n",
    "    files = os.listdir('/home/hadoop/data')\n",
    "    if step<=win:\n",
    "        for i in range(0, filenum):\n",
    "            with open('/home/hadoop/data/%s' % files[i], 'r') as f:\n",
    "                sensordata=np.loadtxt(f, delimiter=\",\")[::2, :]\n",
    "                \n",
    "                ########## feature extraction ###########\n",
    "                sensordata = np.delete(sensordata, np.s_[:3], 1)\n",
    "                sensordata[:, 2] = sensordata[:, 2] - 9.8\n",
    "                sensordata = resample(sensordata, sampling)\n",
    "                \n",
    "                #mi = LA.norm(sensordata, 2, axis=1)\n",
    "                #sma = np.sum(np.abs(sensordata), 1)\n",
    "                #velo = calcVelo(sensordata[:,:2], fs, win)\n",
    "                #sensordata = np.c_[sensordata, mi, sma]\n",
    "                \n",
    "                #loadDataPlot(sensordata, i)\n",
    "                \n",
    "                ########## filter ############\n",
    "                #fltr2(sensordata, cutOff=15, fs=fs, order=5)\n",
    "                #########################################\n",
    "                \n",
    "                max_num=int((len(sensordata)-win)/step)+1\n",
    "                for j in range(0, max_num):\n",
    "                    start_idx=step*j\n",
    "                    end_idx=step*j+win\n",
    "                    sd=sensordata[start_idx:end_idx,:]\n",
    "                    sd=sd.transpose()\n",
    "                        \n",
    "                    time=getTimeColumn(win)\n",
    "                    kindvalue=getKindValueColumn(sd, win)\n",
    "                    travary=np.column_stack((time, kindvalue ))\n",
    "\n",
    "                    if j == 0:\n",
    "                        dataarray=travary\n",
    "                    else:\n",
    "                        dataarray=np.concatenate((dataarray, travary), axis=0)  \n",
    "\n",
    "                labeldict[travel[i]]=i*np.ones((max_num, 1), dtype=int)\n",
    "                datadict[travel[i]]=dataarray\n",
    "                print(files[i]+\" loaded!\")\n",
    "        use_num_max=filenum*max_num\n",
    "        return datadict, labeldict, use_num_max\n",
    "    else:\n",
    "        raise IOError('\\'step\\' of slide window shoud be less than \\'win\\'')\n",
    "\n",
    "#从所有数据dataary和其标签label中，选出总数为num的样本，每个类别选num/sensornum个样本。\n",
    "def genTrainSample(dataary, label, num, win):\n",
    "    idary=getIdColumn(num, win)\n",
    "    labelnum=int(num/filenum) ;\n",
    "    data, y=getDataLabelColumn(dataary, label, labelnum, win)\n",
    "    data=np.column_stack((idary, data))\n",
    "    dataframe = DataFrame(data, columns=['id', 'time', 'kind', 'value'])\n",
    "    return dataframe, y\n",
    "\n",
    "\n",
    "#画出第idx个样本3个传感器的数据\n",
    "def plotSample(data, kind, idx, win, use_num):\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    tmp=data.iloc[:, -1].values\n",
    "    for i in range(sensornum):\n",
    "        plt.subplot(3,2,i+1)\n",
    "        plt.title(sensor[i] + ' readings')\n",
    "        begin=kind*win*use_num + idx*win*sensornum + win*i\n",
    "        end=begin+win-1\n",
    "        plt.plot(tmp[begin:end])\n",
    "    plt.show()\n",
    "    \n",
    "def loadDataPlot(data, ind):\n",
    "    plt.figure(ind)\n",
    "    for i in xrange(0, data.shape[1]):\n",
    "        fig = matplotlib.pyplot.gcf()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        plt.subplot(3,2,i+1)\n",
    "        plt.plot(data[:, i])\n",
    "    return\n",
    "\n",
    "################ Resampling ##################\n",
    "\n",
    "def resample(data, sampling):\n",
    "    tmp = []\n",
    "    for i in xrange(0, 1):\n",
    "        ind = np.arange(i, data.shape[0], sampling)\n",
    "        tmp.append(data[ind, :])\n",
    "    return np.concatenate(tmp, axis=0)\n",
    "\n",
    "################ Calculate Velocity ###################\n",
    "\n",
    "def calcVelo(acc, fs, win):\n",
    "    velo = np.zeros(acc.shape)\n",
    "    for i in xrange(0, acc.shape[0]):\n",
    "        if i % win: \n",
    "            velo[i] = velo[i-1] + (acc[i-1]+acc[i])/(2*fs)\n",
    "    return LA.norm(velo, 2, axis=1)\n",
    "        \n",
    "\n",
    "################ Butterworth 滤波 ###################\n",
    "\n",
    "def butter_lowpass(cutOff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normalCutoff = cutOff / nyq\n",
    "    b, a = butter(order, normalCutoff, btype='low', analog = False)\n",
    "    return b, a\n",
    "\n",
    "def fltr(data, win, sensornum, cutOff, fs, order=5): #这个是在滑窗之后滤波的函数\n",
    "    v = data.iloc[:, -1].values\n",
    "    b, a = butter_lowpass(cutOff, fs, order)\n",
    "    zi = np.tile(lfilter_zi(b, a), (sensornum,1))\n",
    "    for i in xrange(0, v.size, win*sensornum):\n",
    "        for j in xrange(0, sensornum):\n",
    "            x = v[i+j*win: i+(j+1)*win]\n",
    "            y, zi[j]= lfilter(b, a, x, zi=zi[j])\n",
    "            data.iloc[i+j*win: i+(j+1)*win, -1] = y\n",
    "    return\n",
    "\n",
    "def fltr2(sensordata, cutOff, fs, order):  #这个是在数据读取后马上就滤波的函数\n",
    "    b, a = butter_lowpass(cutOff, fs, order)\n",
    "    for n in xrange(sensordata.shape[1]):\n",
    "        zi = lfilter_zi(b, a)\n",
    "        sensordata[:,n], zi = lfilter(b, a, sensordata[:,n], zi=zi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过XGBoost特征提取确定的13大类特征，因考虑不同窗口，采样频率的试验情况，并未采取后续有所缩减的8类特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extraction_settings = {'ar_coefficient': [{'coeff': 0, 'k': 10},\n",
    "    {'coeff': 1, 'k': 10},\n",
    "    {'coeff': 2, 'k': 10},\n",
    "    {'coeff': 3, 'k': 10},\n",
    "    {'coeff': 4, 'k': 10}],\n",
    "          'longest_strike_above_mean': None,\n",
    "          'longest_strike_below_mean': None,\n",
    "          'mean_abs_change_quantiles': [{'qh': 0.2, 'ql': 0.0},\n",
    "                                        {'qh': 0.4, 'ql': 0.0},\n",
    "                                        {'qh': 0.6, 'ql': 0.0},\n",
    "                                        {'qh': 0.8, 'ql': 0.0},\n",
    "                                        {'qh': 1.0, 'ql': 0.0},\n",
    "                                        {'qh': 0.4, 'ql': 0.2},\n",
    "                                        {'qh': 0.6, 'ql': 0.2},\n",
    "                                        {'qh': 0.8, 'ql': 0.2},\n",
    "                                        {'qh': 1.0, 'ql': 0.2},\n",
    "                                        {'qh': 0.6, 'ql': 0.4},\n",
    "                                        {'qh': 0.8, 'ql': 0.4},\n",
    "                                        {'qh': 1.0, 'ql': 0.4},\n",
    "                                        {'qh': 0.8, 'ql': 0.6},\n",
    "                                        {'qh': 1.0, 'ql': 0.6},\n",
    "                                        {'qh': 1.0, 'ql': 0.8}],\n",
    "          'autocorrelation': [{'lag': 0},{'lag': 1},{'lag': 2},{'lag': 3},{'lag': 4},\n",
    "                              {'lag': 5},{'lag': 6},{'lag': 7},{'lag': 8},{'lag': 9}],\n",
    "          'time_reversal_asymmetry_statistic': [{'lag': 1}, {'lag': 2}, {'lag': 3}],\n",
    "          'quantile': [{'q': 0.1},{'q': 0.2},{'q': 0.3},{'q': 0.4},\n",
    "                       {'q': 0.6},{'q': 0.7},{'q': 0.8},{'q': 0.9}],\n",
    "          'number_peaks': [{'n': 1}, {'n': 3}, {'n': 5}],\n",
    "          'minimum': None,\n",
    "          'maximum': None,\n",
    "          'median': None,\n",
    "          'sum_values': None,\n",
    "          'spkt_welch_density': [{'coeff': 2}, {'coeff': 5}, {'coeff': 8}],\n",
    "                    \"fft_dc\":None,\n",
    "                    \"fft_mean\":None,\n",
    "                    #\"fft_var\":None,\n",
    "                    \"fft_std\":None,\n",
    "                    \"fft_kurt\":None,\n",
    "                    \"fft_shape_mean\":None,\n",
    "                    \"fft_shape_std\":None,\n",
    "                    \"fft_shape_skew\":None,\n",
    "                    \"fft_shape_kurt\":None\n",
    "                      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间窗口，（降）采样频率的设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus_data_set_101 loaded!\n",
      "car_data_set_103 loaded!\n",
      "running_data_set_8 loaded!\n",
      "stationary_data_set_3 loaded!\n",
      "subway_data_set_102 loaded!\n",
      "walking_data_set_7 loaded!\n",
      "\n",
      " \u001b[1;33;48m NOTE: use_num should be less than 1206\n"
     ]
    }
   ],
   "source": [
    "#可修改常量\n",
    "# 六种出行方式\n",
    "travel=[\"bus\", \"car\", \"running\", \"stationary\", \"subway\", \"walking\"]\n",
    "# 六个传感器数据\n",
    "sensor=[\"azimath\", \"pitch\", \"roll\"]\n",
    "# 一些常量\n",
    "filenum=6\n",
    "#窗口步长大小\n",
    "#win = [100，200,300,400,500,600]/sample,注意win是在采样间隔基础上算的\n",
    "win=600\n",
    "#步长为时间窗口的一半\n",
    "step=math.ceil(win/2)\n",
    "#sampling[1,2,3,4,5,10,20] ,分别对应100hz，50hz，33hz,25hz，20hz,10hz,5hz\n",
    "sampling=1  #采样间隔\n",
    "\n",
    "sensornum=len(sensor)\n",
    "data, label, use_num_max = loadData(win, step, 0, sampling)\n",
    "\n",
    "print(\"\\n \\033[1;33;48m NOTE: use_num should be less than %s\"%(use_num_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2170800, 4)\n"
     ]
    }
   ],
   "source": [
    "#使用的样本数量(一个窗口的数据是一个样本)，建议设置陈6的倍数\n",
    "use_num =1206\n",
    "#取出use_num个样本，并将data转化成tsfresh需要的pandas.DataFrame类型，存储为df；将label转化为特征过滤需要的pandas.Series类型，存储为y\n",
    "df, y=genTrainSample(data, label, use_num, win)\n",
    "master_df = df\n",
    "print(master_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总特征提取时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 3618/3618 [01:35<00:00, 38.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 s, sys: 198 ms, total: 2.48 s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "# extraction_settings = ComprehensiveFCParameters()\n",
    "#extraction_settings = EfficientFCParameters()\n",
    "# extraction_settings = MinimalFCParameters()\n",
    "#extraction_settings.update({\"fft_dc\":None,\"fft_mean\":None,\"fft_var\":None,\"fft_std\":None,\"fft_kurt\":None,\"fft_shape_mean\":None,\"fft_shape_std\":None,\"fft_shape_skew\":None,\"fft_shape_kurt\":None})\n",
    "%time X = extract_features(master_df, default_fc_parameters=extraction_settings, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "#%time X = extract_features(master_df, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多次重复计算100个窗口特征时间，因为timeit魔术命令总是取三次作为均值，后续并未采用这一数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 36.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:07<00:00, 40.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 7.58 s per loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%timeit Y = extract_features(master_df.ix[0:(win*3*100-1)], default_fc_parameters=extraction_settings, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100个窗口cpu计算时间，重复多次取均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:07<00:00, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 window CPU time for extract_features is 0.296000 s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##100次窗口计算时间\n",
    "cpu_time = 0 #cpu时间\n",
    "for i in xrange(0,5):\n",
    "    start = time.clock()\n",
    "    Y = extract_features(master_df.ix[0:(win*3*100-1)], default_fc_parameters=extraction_settings, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "    end = time.clock()\n",
    "    cpu_time +=end-start\n",
    "print('100 window CPU time for extract_features is %f s '%(cpu_time/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100个窗口程序执行时间，考虑了IO时间。重复多次取均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:07<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:07<00:00, 40.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 36.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 35.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 300/300 [00:08<00:00, 36.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 window execute time for extract_features is 7.000000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "execute_time = 0 #程序执行时间\n",
    "for i in xrange(0,5):\n",
    "    start = datetime.datetime.now()\n",
    "    Y = extract_features(master_df.ix[0:(win*3*100-1)], default_fc_parameters=extraction_settings, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "    end = datetime.datetime.now()\n",
    "    execute_time+= (end-start).seconds\n",
    "print('100 window execute time for extract_features is %f s'%(execute_time/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206, 183)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in X.columns:\n",
    "    std = np.std(X[n])\n",
    "    X[n] = (X[n]-np.mean(X[n]))/std if std>0 else X[n]-np.mean(X[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类XGBoost,Random Forest,Decision Tree,KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost20次随机划分数据集，计算均值及平均混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0, accuracy=0.942149\n",
      "Loop 1, accuracy=0.933884\n",
      "Loop 2, accuracy=0.921488\n",
      "Loop 3, accuracy=0.942149\n",
      "Loop 4, accuracy=0.929752\n",
      "Loop 5, accuracy=0.925620\n",
      "Loop 6, accuracy=0.938017\n",
      "Loop 7, accuracy=0.929752\n",
      "Loop 8, accuracy=0.942149\n",
      "Loop 9, accuracy=0.946281\n",
      "Loop 10, accuracy=0.904959\n",
      "Loop 11, accuracy=0.933884\n",
      "Loop 12, accuracy=0.933884\n",
      "Loop 13, accuracy=0.962810\n",
      "Loop 14, accuracy=0.917355\n",
      "Loop 15, accuracy=0.942149\n",
      "Loop 16, accuracy=0.933884\n",
      "Loop 17, accuracy=0.933884\n",
      "Loop 18, accuracy=0.921488\n",
      "Loop 19, accuracy=0.925620\n",
      "Mean accuracy is 0.933058\n",
      "preds       0      1      2      3     4      5\n",
      "actual                                         \n",
      "0       34.85   2.60   0.25   0.15   1.3   0.25\n",
      "1        1.45  33.15   0.70   0.15   1.5   0.00\n",
      "2        0.00   0.00  38.75   0.00   0.0   0.05\n",
      "3        0.00   0.35   0.00  40.70   0.1   0.00\n",
      "4        3.60   2.30   0.20   0.45  36.8   0.00\n",
      "5        0.05   0.20   0.45   0.00   0.1  41.55\n"
     ]
    }
   ],
   "source": [
    "##XGBoost:重复20次，准确率及混淆矩阵\n",
    "mean = 0\n",
    "for i in xrange(0, 20):\n",
    "    X_train_tmp, X_test, y_train_tmp, y_test = train_test_split(X, y, test_size=.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, y_train_tmp, test_size=.125)\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    cl = XGBClassifier(max_depth=5, n_estimators=200, objective='multi:softmax', reg_lambda=2)\n",
    "    cl.fit(X_train, y_train, eval_metric='mlogloss', eval_set=eval_set, early_stopping_rounds=30, verbose=False)\n",
    "    score = accuracy_score(y_test, cl.predict(X_test))\n",
    "    tempcross=pd.crosstab(cl.predict(X_test), y_test, rownames=['actual'], colnames=['preds'])\n",
    "    print('Loop %d, accuracy=%f' % (i, score))\n",
    "    mean += score\n",
    "    if i==0:\n",
    "        crosstab = tempcross\n",
    "    else:\n",
    "        crosstab = crosstab+tempcross\n",
    "print('Mean accuracy is %f' % (mean/20))\n",
    "print(crosstab/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取随机森林，决策树，KNN三种分类器，同样随机划分20次，取精度均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0, accuracy=0.913223,0.871901,0.900826\n",
      "Loop 1, accuracy=0.921488,0.876033,0.867769\n",
      "Loop 2, accuracy=0.913223,0.851240,0.867769\n",
      "Loop 3, accuracy=0.888430,0.855372,0.855372\n",
      "Loop 4, accuracy=0.913223,0.830579,0.900826\n",
      "Loop 5, accuracy=0.896694,0.851240,0.892562\n",
      "Loop 6, accuracy=0.925620,0.904959,0.871901\n",
      "Loop 7, accuracy=0.921488,0.909091,0.896694\n",
      "Loop 8, accuracy=0.855372,0.855372,0.888430\n",
      "Loop 9, accuracy=0.900826,0.859504,0.884298\n",
      "Loop 10, accuracy=0.867769,0.855372,0.900826\n",
      "Loop 11, accuracy=0.896694,0.855372,0.892562\n",
      "Loop 12, accuracy=0.896694,0.826446,0.863636\n",
      "Loop 13, accuracy=0.917355,0.896694,0.871901\n",
      "Loop 14, accuracy=0.876033,0.859504,0.851240\n",
      "Loop 15, accuracy=0.909091,0.884298,0.904959\n",
      "Loop 16, accuracy=0.946281,0.859504,0.880165\n",
      "Loop 17, accuracy=0.900826,0.880165,0.863636\n",
      "Loop 18, accuracy=0.938017,0.834711,0.838843\n",
      "Loop 19, accuracy=0.925620,0.851240,0.876033\n",
      "RF Mean accuracy is 0.906198\n",
      "DT Mean accuracy is 0.863430\n",
      "KNN Mean accuracy is 0.878512\n"
     ]
    }
   ],
   "source": [
    "mean1 = 0\n",
    "mean2 = 0\n",
    "mean3 = 0\n",
    "for i in xrange(0, 20):\n",
    "    X_train_tmp, X_test, y_train_tmp, y_test = train_test_split(X, y, test_size=.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, y_train_tmp, test_size=.125)\n",
    "    cl1 = RandomForestClassifier()\n",
    "    cl1.fit(X_train, y_train)\n",
    "    score1 = accuracy_score(y_test, cl1.predict(X_test))\n",
    "    cl2 = DecisionTreeClassifier()\n",
    "    cl2.fit(X_train, y_train)\n",
    "    score2 = accuracy_score(y_test, cl2.predict(X_test))\n",
    "    cl3 = neighbors.KNeighborsClassifier()  \n",
    "    cl3.fit(X_train, y_train)\n",
    "    score3 = accuracy_score(y_test, cl3.predict(X_test))\n",
    "    print('Loop %d, accuracy=%f,%f,%f' % (i, score1,score2,score3))\n",
    "    mean1 += score1\n",
    "    mean2 += score2\n",
    "    mean3 += score3\n",
    "print('RF Mean accuracy is %f' % (mean1/20))\n",
    "print('DT Mean accuracy is %f' % (mean2/20))\n",
    "print('KNN Mean accuracy is %f' % (mean3/20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估100个窗口多次预测的平均时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.55 ms per loop\n",
      "1000 loops, best of 3: 963 µs per loop\n",
      "1000 loops, best of 3: 204 µs per loop\n",
      "10 loops, best of 3: 20.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit cl.predict(X_test.iloc[0:99])\n",
    "%timeit cl1.predict(X_test.iloc[0:99])\n",
    "%timeit cl2.predict(X_test.iloc[0:99])\n",
    "%timeit cl3.predict(X_test.iloc[0:99])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
