{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "from tsfresh.examples.har_dataset import download_har_dataset, load_har_dataset, load_har_classes\n",
    "# import seaborn as sns\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import logging\n",
    "\n",
    "#from SFFS import SFFS\n",
    "\n",
    "# We set the logger to Error level\n",
    "# This is not recommend for normal use as you can oversee important Warning messages\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "#根据Win，生成DataFrame格式中的Time列\n",
    "def getTimeColumn(win):\n",
    "    time=np.arange(win)\n",
    "    for idx in range(1, sensornum):\n",
    "        timetmp=np.arange(win)\n",
    "        time=np.concatenate((time, timetmp), axis=0)\n",
    "    time.shape=(len(time),1)\n",
    "    return time\n",
    "\n",
    "#根据Win和数据，生成DataFrame格式中的kind和value列\n",
    "def getKindValueColumn(sd, win):\n",
    "    for i in range(sensornum):\n",
    "        kind=i*np.ones((win, 1),dtype=int)\n",
    "        sensorcols=sd[i]\n",
    "        sensorcols.shape=(win, 1)\n",
    "        sdata=np.column_stack((kind, sensorcols))\n",
    "        if i==0:\n",
    "            sensorframe=sdata\n",
    "        else:\n",
    "            sensorframe=np.row_stack((sensorframe, sdata))\n",
    "    return sensorframe\n",
    "\n",
    "def getIdColumn(num, win):\n",
    "    for i in range(num):\n",
    "        if i==0:\n",
    "            idary=0*np.ones((sensornum*win, 1))\n",
    "        else:\n",
    "            idary=np.row_stack((idary, i*np.ones((sensornum*win, 1))))\n",
    "    return idary\n",
    "\n",
    "def getDataLabelColumn(dataary,label, num, win):\n",
    "    for i in range(filenum):\n",
    "        if i==0:\n",
    "            y=label[travel[i]][:num]\n",
    "            data=dataary[travel[i]][:num*win*sensornum]\n",
    "        else:\n",
    "            y=np.row_stack((y, label[travel[i]][:num]))\n",
    "            data=np.row_stack((data, dataary[travel[i]][:num*win*sensornum]))\n",
    "    y.shape=(len(y),)\n",
    "    y=pd.Series(y)\n",
    "    return data, y\n",
    "\n",
    "#读取所有数据，结果是字典，分别存储六种运动的传感器读数矩阵，每个矩阵的三列分别是time, kind, value\n",
    "def loadData(win):\n",
    "    labeldict={}\n",
    "    datadict={}\n",
    "    files = os.listdir('/home/hadoop/data')\n",
    "    for i in range(0, filenum):\n",
    "        with open('/home/hadoop/data/%s' % files[i], 'r') as f:\n",
    "            sensordata=np.loadtxt(f, delimiter=\",\")\n",
    "            \n",
    "            ########## feature extraction ###########\n",
    "            sensordata = np.delete(sensordata, np.s_[:3], 1)\n",
    "            mi = np.sqrt(np.sum(np.power(sensordata, 2), 1))\n",
    "            sma = np.sum(np.abs(sensordata), 1)\n",
    "            trivial = np.ones((sma.size,))\n",
    "            sensordata = np.c_[sensordata, mi, sma, trivial]\n",
    "            #########################################\n",
    "            \n",
    "            for j in range(0, math.ceil(len(sensordata)/win)):\n",
    "                sd=sensordata[win*j:win*(j+1),:]\n",
    "                sd=sd.transpose()\n",
    "                \n",
    "                time=getTimeColumn(win)\n",
    "                kindvalue=getKindValueColumn(sd, win)\n",
    "                travary=np.column_stack((time, kindvalue ))\n",
    "                \n",
    "                if j == 0:\n",
    "                    dataarray=travary\n",
    "                else:\n",
    "                    dataarray=np.concatenate((dataarray, travary), axis=0)  \n",
    "\n",
    "            labeldict[travel[i]]=i*np.ones((math.ceil(len(sensordata)/win), 1), dtype=int)\n",
    "            datadict[travel[i]]=dataarray\n",
    "            print(files[i]+\" loaded!\")\n",
    "            \n",
    "    return datadict, labeldict\n",
    "\n",
    "#从所有数据dataary和其标签label中，选出总数为num的样本，每个类别选num/sensornum个样本。\n",
    "def genTrainSample(dataary, label, num, win):\n",
    "    idary=getIdColumn(num, win)\n",
    "    labelnum=int(num/sensornum) ;\n",
    "    data, y=getDataLabelColumn(dataary, label, labelnum, win)\n",
    "    data=np.column_stack((idary, data))\n",
    "    dataframe = DataFrame(data, columns=['id', 'time', 'kind', 'value'])\n",
    "    return dataframe, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus_data_set_101 loaded!\n",
      "car_data_set_103 loaded!\n",
      "running_data_set_8 loaded!\n",
      "stationary_data_set_3 loaded!\n",
      "subway_data_set_102 loaded!\n",
      "walking_data_set_7 loaded!\n",
      "(729600, 3)\n",
      "(608, 1)\n",
      "(4320000, 4)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(3600,)\n"
     ]
    }
   ],
   "source": [
    "# 六种出行方式\n",
    "travel=[\"bus\", \"car\", \"running\", \"stationary\", \"subway\", \"walking\"]\n",
    "# 六个传感器数据\n",
    "sensor=[\"azimath\", \"pitch\", \"roll\", \"north\", \"east\", \"up\"]\n",
    "# 一些常量\n",
    "filenum=6\n",
    "sensornum=6\n",
    "#窗口大小\n",
    "win=200\n",
    "#使用的样本数量(一个窗口的数据是一个样本)，建议设置成sensornum的倍数\n",
    "use_num=3600\n",
    "\n",
    "data, label = loadData(win)\n",
    "print(data[\"bus\"].shape)        #data[\"bus]矩阵三列分别是time, kind, value\n",
    "print(label[\"bus\"].shape)       #只有一列，因为sensornum*win条读数才是一个样本，所以label的行数是data的1/(sensornum*win)\n",
    "\n",
    "#取出use_num个样本，并将data转化成tsfresh需要的pandas.DataFrame类型，存储为df；将label转化为特征过滤需要的pandas.Series类型，存储为y\n",
    "df, y=genTrainSample(data, label, use_num, win)    \n",
    "\n",
    "print(df.shape)\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320000, 4)\n",
      "             id   time  kind     value\n",
      "0           0.0    0.0   0.0  0.152070\n",
      "1           0.0    1.0   0.0  0.029368\n",
      "2           0.0    2.0   0.0 -0.098848\n",
      "3           0.0    3.0   0.0  0.066162\n",
      "4           0.0    4.0   0.0  0.053812\n",
      "5           0.0    5.0   0.0 -0.080843\n",
      "6           0.0    6.0   0.0 -0.268438\n",
      "7           0.0    7.0   0.0 -0.342979\n",
      "8           0.0    8.0   0.0 -0.308891\n",
      "9           0.0    9.0   0.0 -0.180185\n",
      "10          0.0   10.0   0.0 -0.016011\n",
      "11          0.0   11.0   0.0 -0.010016\n",
      "12          0.0   12.0   0.0 -0.168150\n",
      "13          0.0   13.0   0.0 -0.318920\n",
      "14          0.0   14.0   0.0 -0.329259\n",
      "15          0.0   15.0   0.0 -0.070470\n",
      "16          0.0   16.0   0.0  0.174845\n",
      "17          0.0   17.0   0.0  0.182681\n",
      "18          0.0   18.0   0.0  0.150804\n",
      "19          0.0   19.0   0.0 -0.082537\n",
      "20          0.0   20.0   0.0 -0.180841\n",
      "21          0.0   21.0   0.0 -0.218992\n",
      "22          0.0   22.0   0.0 -0.006427\n",
      "23          0.0   23.0   0.0  0.133606\n",
      "24          0.0   24.0   0.0  0.198423\n",
      "25          0.0   25.0   0.0  0.063690\n",
      "26          0.0   26.0   0.0 -0.135112\n",
      "27          0.0   27.0   0.0 -0.322740\n",
      "28          0.0   28.0   0.0 -0.351066\n",
      "29          0.0   29.0   0.0 -0.313132\n",
      "...         ...    ...   ...       ...\n",
      "4319970  3599.0  170.0   5.0  1.000000\n",
      "4319971  3599.0  171.0   5.0  1.000000\n",
      "4319972  3599.0  172.0   5.0  1.000000\n",
      "4319973  3599.0  173.0   5.0  1.000000\n",
      "4319974  3599.0  174.0   5.0  1.000000\n",
      "4319975  3599.0  175.0   5.0  1.000000\n",
      "4319976  3599.0  176.0   5.0  1.000000\n",
      "4319977  3599.0  177.0   5.0  1.000000\n",
      "4319978  3599.0  178.0   5.0  1.000000\n",
      "4319979  3599.0  179.0   5.0  1.000000\n",
      "4319980  3599.0  180.0   5.0  1.000000\n",
      "4319981  3599.0  181.0   5.0  1.000000\n",
      "4319982  3599.0  182.0   5.0  1.000000\n",
      "4319983  3599.0  183.0   5.0  1.000000\n",
      "4319984  3599.0  184.0   5.0  1.000000\n",
      "4319985  3599.0  185.0   5.0  1.000000\n",
      "4319986  3599.0  186.0   5.0  1.000000\n",
      "4319987  3599.0  187.0   5.0  1.000000\n",
      "4319988  3599.0  188.0   5.0  1.000000\n",
      "4319989  3599.0  189.0   5.0  1.000000\n",
      "4319990  3599.0  190.0   5.0  1.000000\n",
      "4319991  3599.0  191.0   5.0  1.000000\n",
      "4319992  3599.0  192.0   5.0  1.000000\n",
      "4319993  3599.0  193.0   5.0  1.000000\n",
      "4319994  3599.0  194.0   5.0  1.000000\n",
      "4319995  3599.0  195.0   5.0  1.000000\n",
      "4319996  3599.0  196.0   5.0  1.000000\n",
      "4319997  3599.0  197.0   5.0  1.000000\n",
      "4319998  3599.0  198.0   5.0  1.000000\n",
      "4319999  3599.0  199.0   5.0  1.000000\n",
      "\n",
      "[4320000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "master_df = df\n",
    "\n",
    "print(master_df.shape)\n",
    "print(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 6/6 [1:00:48<00:00, 585.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 364 ms, total: 2.26 s\n",
      "Wall time: 1h 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([u'0.0__mean_abs_change_quantiles__qh_1.0__ql_0.8',\n",
       "                                            u'0.0__mean',\n",
       "                u'0.0__large_standard_deviation__r_0.35',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_1.0__ql_0.4',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_1.0__ql_0.6',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_1.0__ql_0.0',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_1.0__ql_0.2',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_0.6__ql_0.8',\n",
       "                                u'0.0__count_above_mean',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_0.6__ql_0.2',\n",
       "       ...\n",
       "                        u'4.0__fft_coefficient__coeff_0',\n",
       "                        u'4.0__fft_coefficient__coeff_1',\n",
       "                        u'4.0__fft_coefficient__coeff_2',\n",
       "                        u'4.0__fft_coefficient__coeff_3',\n",
       "                        u'4.0__fft_coefficient__coeff_4',\n",
       "                        u'4.0__fft_coefficient__coeff_5',\n",
       "                        u'4.0__fft_coefficient__coeff_6',\n",
       "                        u'4.0__fft_coefficient__coeff_7',\n",
       "                        u'4.0__fft_coefficient__coeff_8',\n",
       "                        u'4.0__fft_coefficient__coeff_9'],\n",
       "      dtype='object', length=1614)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraction_settings = ComprehensiveFCParameters()\n",
    "extraction_settings = EfficientFCParameters()\n",
    "# extraction_settings = MinimalFCParameters()\n",
    "\n",
    "%time X = extract_features(master_df, default_fc_parameters=extraction_settings, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "# %time X = extract_features(master_df, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "\n",
    "# in total we have transformed the sensor data into 222 features\n",
    "impute(X)\n",
    "X.shape\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_X = X.loc[:, X.columns[:-269]] #Only extract the features about accelerometer\n",
    "X_train, X_test, y_train, y_test = train_test_split(sub_X, y, test_size=.2)\n",
    "X_train_fs, X_val, y_train_fs, y_val = train_test_split(X_train, y_train, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Sequential Floating Forward Selection, the evaluation is based on Random Forest\n",
    "def SFFS(X_train, y_train, X_val, y_val):\n",
    "    column = X_train.columns\n",
    "    ftr = np.array([])\n",
    "    ind = np.zeros(column.shape, dtype=bool)\n",
    "    max_score = 0\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while ftr.size < column.shape[0] and max_score < 1:\n",
    "        ## Forward\n",
    "        max_score_forward = max_score\n",
    "        select_ftr = -1\n",
    "        for i, col in enumerate(ind):\n",
    "            if col:\n",
    "                continue\n",
    "            else:\n",
    "                tmp_ftr = np.append(ftr, column[i])\n",
    "                max_score_forward, select_ftr = evaFtr(X_train, y_train, X_val, y_val,\n",
    "                                                        tmp_ftr, i, max_score_forward, select_ftr)\n",
    "        if select_ftr >= 0:\n",
    "            ftr = np.append(ftr, column[select_ftr])\n",
    "            ind[select_ftr] = True\n",
    "\n",
    "        ## Backward\n",
    "        max_score_backward = max_score_forward\n",
    "        while ftr.size > 1:\n",
    "            select_ftr = -1\n",
    "            for i, n in enumerate(ftr):\n",
    "                tmp_ftr = np.delete(ftr, i)\n",
    "                max_score_backward, select_ftr = evaFtr(X_train, y_train, X_val, y_val,\n",
    "                                                        tmp_ftr, i, max_score_backward, select_ftr)\n",
    "            if select_ftr >= 0:\n",
    "                ftr = np.delete(ftr, select_ftr)\n",
    "                #ind[select_ftr] = False\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        count += 1\n",
    "        print('Loop = %d, Maximum Score = %f, Feature Num = %s' % (count, max(max_score,max_score_backward), ftr.size))\n",
    "\n",
    "        if max_score < max_score_backward:\n",
    "            max_score = max_score_backward\n",
    "        else:\n",
    "            print('Feature Selection Completed!')\n",
    "            break\n",
    "        \n",
    "    return ftr\n",
    "\n",
    "\n",
    "def evaFtr(X_train, y_train, X_val, y_val, tmp_ftr, i, max_score, select_ftr):\n",
    "        tmp_X_train = X_train.loc[:, tmp_ftr]\n",
    "        tmp_X_val = X_val.loc[:, tmp_ftr]\n",
    "        cl = RandomForestClassifier()\n",
    "        cl.fit(tmp_X_train, y_train)\n",
    "        score = accuracy_score(y_val, cl.predict(tmp_X_val))\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            select_ftr = i\n",
    "        return max_score, select_ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop = 1, Maximum Score = 0.641667, Feature Num = 1\n",
      "Loop = 2, Maximum Score = 0.781944, Feature Num = 2\n",
      "Loop = 3, Maximum Score = 0.837500, Feature Num = 3\n",
      "Loop = 4, Maximum Score = 0.863889, Feature Num = 4\n",
      "Loop = 5, Maximum Score = 0.870833, Feature Num = 5\n",
      "Loop = 6, Maximum Score = 0.870833, Feature Num = 5\n",
      "Feature Selection Completed!\n"
     ]
    }
   ],
   "source": [
    "ftr = SFFS(X_train_fs, y_train_fs, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data is 0.847222\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the selected features based on Random Forest\n",
    "tmp_X_train = X_train.loc[:, ftr]\n",
    "tmp_X_test = X_test.loc[:, ftr]\n",
    "cl = RandomForestClassifier()\n",
    "cl.fit(tmp_X_train, y_train)\n",
    "score = accuracy_score(y_test, cl.predict(tmp_X_test))\n",
    "print('Accuracy of test data is %f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of missclassification is 220\n",
      "Num of missclassification from Motor is 172\n"
     ]
    }
   ],
   "source": [
    "y_prdct = cl.predict(tmp_X_test)\n",
    "ind = np.nonzero(y_test.values != y_prdct)\n",
    "error = np.c_[y_test.values[ind], y_prdct[ind]]\n",
    "print('Total num of missclassification is %d' % error.size)\n",
    "\n",
    "dlt = []\n",
    "dct = [2, 3, 5]\n",
    "for i, n in enumerate(error):\n",
    "    if n[0] in dct or n[1] in dct:\n",
    "        dlt.append(i)\n",
    "motor_error = np.delete(error, dlt, 0)\n",
    "print('Num of missclassification from Motor is %d' % motor_error.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'2.0__variance', u'2.0__sum_values', u'2.0__mean_autocorrelation',\n",
       "       u'0.0__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_6__w_2',\n",
       "       u'1.0__mean_abs_change_quantiles__qh_0.8__ql_0.0',\n",
       "       u'5.0__friedrich_coefficients__m_3__r_30__coeff_3'], \n",
       "      dtype='<U58')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876388888889\n"
     ]
    }
   ],
   "source": [
    "#Using all the features as contrast\n",
    "cl = RandomForestClassifier()\n",
    "cl.fit(X_train, y_train)\n",
    "score = accuracy_score(y_test, cl.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
