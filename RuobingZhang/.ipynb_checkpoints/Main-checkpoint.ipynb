{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "from tsfresh.examples.har_dataset import download_har_dataset, load_har_dataset, load_har_classes\n",
    "# import seaborn as sns\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import logging\n",
    "\n",
    "#from SFFS import SFFS\n",
    "\n",
    "# We set the logger to Error level\n",
    "# This is not recommend for normal use as you can oversee important Warning messages\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "#根据Win，生成DataFrame格式中的Time列\n",
    "def getTimeColumn(win):\n",
    "    time=np.arange(win)\n",
    "    for idx in range(1, sensornum):\n",
    "        timetmp=np.arange(win)\n",
    "        time=np.concatenate((time, timetmp), axis=0)\n",
    "    time.shape=(len(time),1)\n",
    "    return time\n",
    "\n",
    "#根据Win和数据，生成DataFrame格式中的kind和value列\n",
    "def getKindValueColumn(sd, win):\n",
    "    for i in range(sensornum):\n",
    "        kind=i*np.ones((win, 1),dtype=int)\n",
    "        sensorcols=sd[i]\n",
    "        sensorcols.shape=(win, 1)\n",
    "        sdata=np.column_stack((kind, sensorcols))\n",
    "        if i==0:\n",
    "            sensorframe=sdata\n",
    "        else:\n",
    "            sensorframe=np.row_stack((sensorframe, sdata))\n",
    "    return sensorframe\n",
    "\n",
    "def getIdColumn(num, win):\n",
    "    for i in range(num):\n",
    "        if i==0:\n",
    "            idary=0*np.ones((sensornum*win, 1))\n",
    "        else:\n",
    "            idary=np.row_stack((idary, i*np.ones((sensornum*win, 1))))\n",
    "    return idary\n",
    "\n",
    "def getDataLabelColumn(dataary,label, num, win):\n",
    "    for i in range(filenum):\n",
    "        if i==0:\n",
    "            y=label[travel[i]][:num]\n",
    "            data=dataary[travel[i]][:num*win*sensornum]\n",
    "        else:\n",
    "            y=np.row_stack((y, label[travel[i]][:num]))\n",
    "            data=np.row_stack((data, dataary[travel[i]][:num*win*sensornum]))\n",
    "    y.shape=(len(y),)\n",
    "    y=pd.Series(y)\n",
    "    return data, y\n",
    "\n",
    "#读取所有数据，结果是字典，分别存储六种运动的传感器读数矩阵，每个矩阵的三列分别是time, kind, value\n",
    "def loadData(win):\n",
    "    labeldict={}\n",
    "    datadict={}\n",
    "    files = os.listdir('/home/hadoop/data')\n",
    "    for i in range(0, filenum):\n",
    "        with open('/home/hadoop/data/%s' % files[i], 'r') as f:\n",
    "            sensordata=np.loadtxt(f, delimiter=\",\")\n",
    "            for j in range(0, math.ceil(len(sensordata)/win)):\n",
    "                sd=sensordata[win*j:win*(j+1),:]\n",
    "                sd=sd.transpose()\n",
    "                \n",
    "                time=getTimeColumn(win)\n",
    "                kindvalue=getKindValueColumn(sd, win)\n",
    "                travary=np.column_stack((time, kindvalue ))\n",
    "                \n",
    "                if j == 0:\n",
    "                    dataarray=travary\n",
    "                else:\n",
    "                    dataarray=np.concatenate((dataarray, travary), axis=0)  \n",
    "\n",
    "            labeldict[travel[i]]=i*np.ones((math.ceil(len(sensordata)/win), 1), dtype=int)\n",
    "            datadict[travel[i]]=dataarray\n",
    "            print(files[i]+\" loaded!\")\n",
    "            \n",
    "    return datadict, labeldict\n",
    "\n",
    "#从所有数据dataary和其标签label中，选出总数为num的样本，每个类别选num/sensornum个样本。\n",
    "def genTrainSample(dataary, label, num, win):\n",
    "    idary=getIdColumn(num, win)\n",
    "    labelnum=int(num/sensornum) ;\n",
    "    data, y=getDataLabelColumn(dataary, label, labelnum, win)\n",
    "    data=np.column_stack((idary, data))\n",
    "    dataframe = DataFrame(data, columns=['id', 'time', 'kind', 'value'])\n",
    "    return dataframe, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus_data_set_101 loaded!\n",
      "car_data_set_103 loaded!\n",
      "running_data_set_8 loaded!\n",
      "stationary_data_set_3 loaded!\n",
      "subway_data_set_102 loaded!\n",
      "walking_data_set_7 loaded!\n",
      "(729900, 3)\n",
      "(811, 1)\n",
      "(4320000, 4)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(4800,)\n"
     ]
    }
   ],
   "source": [
    "# 六种出行方式\n",
    "travel=[\"bus\", \"car\", \"running\", \"stationary\", \"subway\", \"walking\"]\n",
    "# 六个传感器数据\n",
    "sensor=[\"azimath\", \"pitch\", \"roll\", \"north\", \"east\", \"up\"]\n",
    "# 一些常量\n",
    "filenum=6\n",
    "sensornum=6\n",
    "#窗口大小\n",
    "win=150\n",
    "#使用的样本数量(一个窗口的数据是一个样本)，建议设置陈6的倍数\n",
    "use_num=4800\n",
    "\n",
    "data, label = loadData(win)\n",
    "print(data[\"bus\"].shape)        #data[\"bus]矩阵三列分别是time, kind, value\n",
    "print(label[\"bus\"].shape)       #只有一列，因为sensornum*win条读数才是一个样本，所以label的行数是data的1/(sensornum*win)\n",
    "\n",
    "#取出use_num个样本，并将data转化成tsfresh需要的pandas.DataFrame类型，存储为df；将label转化为特征过滤需要的pandas.Series类型，存储为y\n",
    "df, y=genTrainSample(data, label, use_num, win)    \n",
    "\n",
    "print(df.shape)\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320000, 4)\n",
      "             id   time  kind      value\n",
      "0           0.0    0.0   0.0   1.202669\n",
      "1           0.0    1.0   0.0   1.200916\n",
      "2           0.0    2.0   0.0   1.191972\n",
      "3           0.0    3.0   0.0   1.186100\n",
      "4           0.0    4.0   0.0   1.181217\n",
      "5           0.0    5.0   0.0   1.191511\n",
      "6           0.0    6.0   0.0   1.197771\n",
      "7           0.0    7.0   0.0   1.205506\n",
      "8           0.0    8.0   0.0   1.201536\n",
      "9           0.0    9.0   0.0   1.206752\n",
      "10          0.0   10.0   0.0   1.189720\n",
      "11          0.0   11.0   0.0   1.188346\n",
      "12          0.0   12.0   0.0   1.182130\n",
      "13          0.0   13.0   0.0   1.191688\n",
      "14          0.0   14.0   0.0   1.189974\n",
      "15          0.0   15.0   0.0   1.203741\n",
      "16          0.0   16.0   0.0   1.204384\n",
      "17          0.0   17.0   0.0   1.202886\n",
      "18          0.0   18.0   0.0   1.189893\n",
      "19          0.0   19.0   0.0   1.186932\n",
      "20          0.0   20.0   0.0   1.184310\n",
      "21          0.0   21.0   0.0   1.179736\n",
      "22          0.0   22.0   0.0   1.178087\n",
      "23          0.0   23.0   0.0   1.178802\n",
      "24          0.0   24.0   0.0   1.164416\n",
      "25          0.0   25.0   0.0   1.168749\n",
      "26          0.0   26.0   0.0   1.167735\n",
      "27          0.0   27.0   0.0   1.170264\n",
      "28          0.0   28.0   0.0   1.174926\n",
      "29          0.0   29.0   0.0   1.190670\n",
      "...         ...    ...   ...        ...\n",
      "4319970  4799.0  120.0   5.0  17.695370\n",
      "4319971  4799.0  121.0   5.0  17.698029\n",
      "4319972  4799.0  122.0   5.0  15.596107\n",
      "4319973  4799.0  123.0   5.0  14.695793\n",
      "4319974  4799.0  124.0   5.0  13.297612\n",
      "4319975  4799.0  125.0   5.0  12.696543\n",
      "4319976  4799.0  126.0   5.0  11.591116\n",
      "4319977  4799.0  127.0   5.0  10.494803\n",
      "4319978  4799.0  128.0   5.0   9.963858\n",
      "4319979  4799.0  129.0   5.0   9.729324\n",
      "4319980  4799.0  130.0   5.0   9.187793\n",
      "4319981  4799.0  131.0   5.0   9.046803\n",
      "4319982  4799.0  132.0   5.0   8.284714\n",
      "4319983  4799.0  133.0   5.0   8.300776\n",
      "4319984  4799.0  134.0   5.0   7.637084\n",
      "4319985  4799.0  135.0   5.0   7.288893\n",
      "4319986  4799.0  136.0   5.0   6.521245\n",
      "4319987  4799.0  137.0   5.0   6.304478\n",
      "4319988  4799.0  138.0   5.0   5.704894\n",
      "4319989  4799.0  139.0   5.0   5.728589\n",
      "4319990  4799.0  140.0   5.0   5.331394\n",
      "4319991  4799.0  141.0   5.0   4.898034\n",
      "4319992  4799.0  142.0   5.0   4.759709\n",
      "4319993  4799.0  143.0   5.0   4.128727\n",
      "4319994  4799.0  144.0   5.0   4.066446\n",
      "4319995  4799.0  145.0   5.0   3.650816\n",
      "4319996  4799.0  146.0   5.0   3.582377\n",
      "4319997  4799.0  147.0   5.0   3.113166\n",
      "4319998  4799.0  148.0   5.0   3.170561\n",
      "4319999  4799.0  149.0   5.0   2.992676\n",
      "\n",
      "[4320000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "master_df = df\n",
    "\n",
    "print(master_df.shape)\n",
    "print(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 6/6 [1:45:05<00:00, 1030.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 s, sys: 908 ms, total: 3.86 s\n",
      "Wall time: 1h 45min 8s\n"
     ]
    }
   ],
   "source": [
    "# extraction_settings = ComprehensiveFCParameters()\n",
    "extraction_settings = EfficientFCParameters()\n",
    "# extraction_settings = MinimalFCParameters()\n",
    "\n",
    "%time X = extract_features(master_df, default_fc_parameters=extraction_settings, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "# %time X = extract_features(master_df, column_id='id', column_sort=\"time\", column_kind=\"kind\", column_value=\"value\");\n",
    "\n",
    "# in total we have transformed the sensor data into 222 features\n",
    "impute(X)\n",
    "X.shape\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train_fs, X_val, y_train_fs, y_val = train_test_split(X_train, y_train, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Sequential Floating Forward Selection, the evaluation is based on Random Forest\n",
    "def SFFS(X_train_fs, y_train_fs, X_val, y_val):\n",
    "    column = X_train.columns\n",
    "    ftr = np.array([])\n",
    "    ind = np.zeros(column.shape, dtype=bool)\n",
    "    max_score = 0\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while ftr.size < column.shape[0] and max_score < 1:\n",
    "        ## Forward\n",
    "        max_score_forward = max_score\n",
    "        select_ftr = -1\n",
    "        for i, col in enumerate(ind):\n",
    "            if col:\n",
    "                continue\n",
    "            else:\n",
    "                tmp_ftr = np.append(ftr, column[i])\n",
    "                max_score_forward, select_ftr = evaFtr(X_train, y_train, X_val, y_val,\n",
    "                                                        tmp_ftr, i, max_score_forward, select_ftr)\n",
    "        if select_ftr >= 0:\n",
    "            ftr = np.append(ftr, column[select_ftr])\n",
    "            ind[select_ftr] = True\n",
    "\n",
    "        ## Backward\n",
    "        max_score_backward = max_score_forward\n",
    "        while ftr.size > 1:\n",
    "            select_ftr = -1\n",
    "            for i, n in enumerate(ftr):\n",
    "                tmp_ftr = np.delete(ftr, i)\n",
    "                max_score_backward, select_ftr = evaFtr(X_train, y_train, X_val, y_val,\n",
    "                                                        tmp_ftr, i, max_score_backward, select_ftr)\n",
    "            if select_ftr >= 0:\n",
    "                ftr = np.delete(ftr, select_ftr)\n",
    "                #ind[select_ftr] = False\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        count += 1\n",
    "        print('Loop = %d, Maximum Score = %f, Feature Num = %s' % (count, max(max_score,max_score_backward), ftr.size))\n",
    "\n",
    "        if max_score < max_score_backward:\n",
    "            max_score = max_score_backward\n",
    "        else:\n",
    "            print('Feature Selection Completed!')\n",
    "            break\n",
    "        \n",
    "    return ftr\n",
    "\n",
    "\n",
    "def evaFtr(X_train, y_train, X_val, y_val, tmp_ftr, i, max_score, select_ftr):\n",
    "        tmp_X_train = X_train.loc[:, tmp_ftr]\n",
    "        tmp_X_val = X_val.loc[:, tmp_ftr]\n",
    "        cl = RandomForestClassifier()\n",
    "        cl.fit(tmp_X_train, y_train)\n",
    "        score = accuracy_score(y_val, cl.predict(tmp_X_val))\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            select_ftr = i\n",
    "        return max_score, select_ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop = 1, Maximum Score = 0.621875, Feature Num = 1\n",
      "Loop = 2, Maximum Score = 0.820833, Feature Num = 2\n",
      "Loop = 3, Maximum Score = 0.903125, Feature Num = 3\n",
      "Loop = 4, Maximum Score = 0.925000, Feature Num = 4\n",
      "Loop = 5, Maximum Score = 0.938542, Feature Num = 5\n",
      "Loop = 6, Maximum Score = 0.944792, Feature Num = 6\n",
      "Loop = 7, Maximum Score = 0.957292, Feature Num = 7\n",
      "Loop = 8, Maximum Score = 0.962500, Feature Num = 8\n",
      "Loop = 9, Maximum Score = 0.962500, Feature Num = 8\n",
      "Feature Selection Completed!\n"
     ]
    }
   ],
   "source": [
    "ftr = SFFS(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data is 0.948958\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the selected features based on Random Forest\n",
    "tmp_X_train = X_train.loc[:, ftr]\n",
    "tmp_X_test = X_test.loc[:, ftr]\n",
    "cl = RandomForestClassifier()\n",
    "cl.fit(tmp_X_train, y_train)\n",
    "score = accuracy_score(y_test, cl.predict(tmp_X_test))\n",
    "print('Accuracy of test data is %f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'5.0__linear_trend__attr_\"stderr\"', u'0.0__median',\n",
       "       u'2.0__sum_values', u'1.0__quantile__q_0.1',\n",
       "       u'5.0__agg_linear_trend__f_agg_\"mean\"__chunk_len_5__attr_\"intercept\"',\n",
       "       u'0.0__mean_abs_change_quantiles__qh_1.0__ql_0.2',\n",
       "       u'5.0__autocorrelation__lag_1', u'5.0__median'], \n",
       "      dtype='<U66')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "#Using all the features as contrast\n",
    "cl = RandomForestClassifier()\n",
    "cl.fit(X_train, y_train)\n",
    "score = accuracy_score(y_test, cl.predict(X_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
